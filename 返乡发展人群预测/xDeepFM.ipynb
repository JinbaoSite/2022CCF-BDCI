{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fceb772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinbao\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c08488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape = (59872, 48)\n",
      "test_data.shape  = (49858, 47)\n",
      "data_nolabel.shape  = (39884, 47)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/dataTrain.csv')\n",
    "test_data = pd.read_csv('data/dataA.csv')\n",
    "submission = pd.read_csv('data/submit_example_A.csv')\n",
    "data_nolabel = pd.read_csv('data/dataNoLabel.csv')\n",
    "print(f'train_data.shape = {train_data.shape}')\n",
    "print(f'test_data.shape  = {test_data.shape}')\n",
    "print(f'data_nolabel.shape  = {data_nolabel.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84672d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['f47'] = train_data['f1'] * 10 + train_data['f2']\n",
    "test_data['f47'] = test_data['f1'] * 10 + test_data['f2']\n",
    "# 暴力Feature 位置\n",
    "loc_f = ['f1', 'f2', 'f4', 'f5', 'f6']\n",
    "for df in [train_data, test_data]:\n",
    "    for i in range(len(loc_f)):\n",
    "        for j in range(i + 1, len(loc_f)):\n",
    "            df[f'{loc_f[i]}+{loc_f[j]}'] = df[loc_f[i]] + df[loc_f[j]]\n",
    "            df[f'{loc_f[i]}-{loc_f[j]}'] = df[loc_f[i]] - df[loc_f[j]]\n",
    "            df[f'{loc_f[i]}*{loc_f[j]}'] = df[loc_f[i]] * df[loc_f[j]]\n",
    "            df[f'{loc_f[i]}/{loc_f[j]}'] = df[loc_f[i]] / (df[loc_f[j]]+1)\n",
    "\n",
    "# 暴力Feature 通话\n",
    "com_f = ['f43', 'f44', 'f45', 'f46']\n",
    "for df in [train_data, test_data]:\n",
    "    for i in range(len(com_f)):\n",
    "        for j in range(i + 1, len(com_f)):\n",
    "            df[f'{com_f[i]}+{com_f[j]}'] = df[com_f[i]] + df[com_f[j]]\n",
    "            df[f'{com_f[i]}-{com_f[j]}'] = df[com_f[i]] - df[com_f[j]]\n",
    "            df[f'{com_f[i]}*{com_f[j]}'] = df[com_f[i]] * df[com_f[j]]\n",
    "            df[f'{com_f[i]}/{com_f[j]}'] = df[com_f[i]] / (df[com_f[j]]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f967ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['f3']\n",
    "data = pd.concat([train_data, test_data])\n",
    "\n",
    "for col in cat_columns:\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(data[col])\n",
    "    train_data[col] = lb.transform(train_data[col])\n",
    "    test_data[col] = lb.transform(test_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c3c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = [ col for col in train_data.columns if col not in ['id', 'label', 'f3']]\n",
    "feature_columns = num_columns + cat_columns\n",
    "target = 'label'\n",
    "\n",
    "train = train_data[feature_columns][:50000]\n",
    "label = train_data[target][:50000]\n",
    "test = test_data[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3db26c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.out_layer = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        output = self.out_layer(inputs)\n",
    "        return output\n",
    "\n",
    "class Dense_layer(Layer):\n",
    "    def __init__(self, hidden_units, out_dim=1, activation='relu', dropout=0.0):\n",
    "        super(Dense_layer, self).__init__()\n",
    "        self.hidden_layers = [Dense(i, activation=activation) for i in hidden_units]\n",
    "        self.out_layer = Dense(out_dim, activation=None)\n",
    "        self.dropout = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # inputs: [None, n*k]\n",
    "        x = inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.dropout(x)\n",
    "        output = self.out_layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b03447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIN(Layer):\n",
    "    def __init__(self, cin_size):\n",
    "        super(CIN, self).__init__()\n",
    "        self.cin_size = cin_size  # 每层的矩阵个数\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: [None, n, k]\n",
    "        self.field_num = [input_shape[1]] + self.cin_size # 每层的矩阵个数(包括第0层)\n",
    "\n",
    "        self.cin_W = [self.add_weight(\n",
    "                         name='w'+str(i),\n",
    "                         shape=(1, self.field_num[0]*self.field_num[i], self.field_num[i+1]),\n",
    "                         initializer=tf.initializers.glorot_uniform(),\n",
    "                         regularizer=tf.keras.regularizers.l1_l2(1e-5),\n",
    "                         trainable=True)\n",
    "                      for i in range(len(self.field_num)-1)]\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # inputs: [None, n, k]\n",
    "        k = inputs.shape[-1]\n",
    "        res_list = [inputs]\n",
    "        X0 = tf.split(inputs, k, axis=-1)           # 最后维切成k份，list: k * [None, field_num[0], 1]\n",
    "        for i, size in enumerate(self.field_num[1:]):\n",
    "            Xi = tf.split(res_list[-1], k, axis=-1) # list: k * [None, field_num[i], 1]\n",
    "            x = tf.matmul(X0, Xi, transpose_b=True) # list: k * [None, field_num[0], field_num[i]]\n",
    "            x = tf.reshape(x, shape=[k, -1, self.field_num[0]*self.field_num[i]])\n",
    "                                                    # [k, None, field_num[0]*field_num[i]]\n",
    "            x = tf.transpose(x, [1, 0, 2])          # [None, k, field_num[0]*field_num[i]]\n",
    "            x = tf.nn.conv1d(input=x, filters=self.cin_W[i], stride=1, padding='VALID')\n",
    "                                                    # (None, k, field_num[i+1])\n",
    "            x = tf.transpose(x, [0, 2, 1])          # (None, field_num[i+1], k)\n",
    "            res_list.append(x)\n",
    "\n",
    "        res_list = res_list[1:]   # 去掉X0\n",
    "        res = tf.concat(res_list, axis=1)  # (None, field_num[1]+...+field_num[n], k)\n",
    "        output = tf.reduce_sum(res, axis=-1)  # (None, field_num[1]+...+field_num[n])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37588ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class xDeepFM(Model):\n",
    "    def __init__(self, feature_columns, cin_size, hidden_units, out_dim=1, activation='relu', dropout=0.0):\n",
    "        super(xDeepFM, self).__init__()\n",
    "        self.dense_feature_columns, self.sparse_feature_columns = feature_columns\n",
    "        self.embed_layers = [Embedding(feat['feat_onehot_dim'], feat['embed_dim'])\n",
    "                                    for feat in self.sparse_feature_columns]\n",
    "        self.linear = Linear()\n",
    "        self.dense_layer = Dense_layer(hidden_units, out_dim, activation, dropout)\n",
    "        self.cin_layer = CIN(cin_size)\n",
    "        self.out_layer = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        dense_inputs, sparse_inputs = inputs[:, :13], inputs[:, 13:]\n",
    "\n",
    "        # linear\n",
    "        linear_out = self.linear(inputs)\n",
    "\n",
    "        emb = [self.embed_layers[i](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])] # [n, None, k]\n",
    "        emb = tf.transpose(tf.convert_to_tensor(emb), [1, 0, 2]) # [None, n, k]\n",
    "\n",
    "        # CIN\n",
    "        cin_out = self.cin_layer(emb)\n",
    "\n",
    "        # dense\n",
    "        emb = tf.reshape(emb, shape=(-1, emb.shape[1]*emb.shape[2]))\n",
    "        emb = tf.concat([dense_inputs, emb], axis=1)\n",
    "        dense_out = self.dense_layer(emb)\n",
    "\n",
    "        output = self.out_layer(linear_out + cin_out + dense_out)\n",
    "        return tf.nn.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6db3f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def sparseFeature(feat, feat_onehot_dim, embed_dim):\n",
    "    return {'feat': feat, 'feat_onehot_dim': feat_onehot_dim, 'embed_dim': embed_dim}\n",
    "\n",
    "def denseFeature(feat):\n",
    "    return {'feat': feat}\n",
    "\n",
    "def create_dataset(data, embed_dim=8, test_size=0.2):\n",
    "#     data = pd.read_csv(file_path)\n",
    "\n",
    "    dense_features = num_columns\n",
    "    sparse_features = cat_columns\n",
    "\n",
    "    #缺失值填充\n",
    "    data[dense_features] = data[dense_features].fillna(0)\n",
    "    data[sparse_features] = data[sparse_features].fillna('-1')\n",
    "\n",
    "    #归一化\n",
    "    data[dense_features] = MinMaxScaler().fit_transform(data[dense_features])\n",
    "    #LabelEncoding编码\n",
    "    for col in sparse_features:\n",
    "        data[col] = LabelEncoder().fit_transform(data[col]).astype(int)\n",
    "\n",
    "    feature_columns = [[denseFeature(feat) for feat in dense_features]] + \\\n",
    "           [[sparseFeature(feat, data[feat].nunique(), embed_dim) for feat in sparse_features]]\n",
    "\n",
    "    X = data.drop(['label'], axis=1).values\n",
    "    y = data['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    return feature_columns, (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd80bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses, optimizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_size = 0.2\n",
    "hidden_units = [256, 128, 64]\n",
    "dropout = 0.3\n",
    "cin_size = [128, 128]\n",
    "\n",
    "feature_columns, (X_train, y_train), (X_test, y_test) = create_dataset(train_data[:50000], test_size=test_size)\n",
    "\n",
    "model = xDeepFM(feature_columns, cin_size, hidden_units, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bc608cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=3, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=0](Placeholder, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [120], [2], [2], [2] and with computed input tensors: input[3] = <1 1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:509\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can only call `build()` on a model if its \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`call()` method accepts an `inputs` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    507\u001b[0m     )\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mInvalidArgumentError, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot build your model by calling `build` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif your layers do not support float type inputs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`call` is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    518\u001b[0m     )\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mxDeepFM.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 13\u001b[0m     dense_inputs, sparse_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m]\u001b[49m, inputs[:, \u001b[38;5;241m13\u001b[39m:]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# linear\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     linear_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1969\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1966\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1968\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1969\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[0;32m   1972\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[0;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[1;31mValueError\u001b[0m: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=3, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=0](Placeholder, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [120], [2], [2], [2] and with computed input tensors: input[3] = <1 1>."
     ]
    }
   ],
   "source": [
    "model.build(input_shape=(120,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.SGD(0.01)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.batch(1024).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer('E:\\\\PycharmProjects\\\\tensorboard')\n",
    "for epoch in range(30):\n",
    "    loss_summary = []\n",
    "    for batch, data_batch in enumerate(train_dataset):\n",
    "            X_train, y_train = data_batch[0], data_batch[1]\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pre = model(X_train)\n",
    "                loss = tf.reduce_mean(losses.binary_crossentropy(y_true=y_train, y_pred=y_pre))\n",
    "                grad = tape.gradient(loss, model.variables)\n",
    "                optimizer.apply_gradients(grads_and_vars=zip(grad, model.variables))\n",
    "            if batch%10==0:\n",
    "                print('epoch: {} batch: {} loss: {}'.format(epoch, batch, loss.numpy()))\n",
    "            loss_summary.append(loss.numpy())\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar(\"loss\", np.mean(loss_summary), step=epoch)\n",
    "\n",
    "pre = model(X_test)\n",
    "pre = [1 if x>0.5 else 0 for x in pre]\n",
    "print(\"Accuracy: \", accuracy_score(y_test, pre))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
